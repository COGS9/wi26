---
layout: default
title: Reading 5
has_children: false
parent: ðŸ“š Readings
nav_order: 5
permalink: /readings/reading-5
---

# Reading 5

- Nicholas Diakopoulos, 2016, Accountability in Algorithmic Decision Making <a href="https://s3.us-west-2.amazonaws.com/ucsd.cogs9/readings/r5a-algorithmic-decision-making.pdf" target="_blank" rel="noopener">download &#x2197;</a>
- Julia Angwin, et al., 2016, Machine Bias <a href="https://s3.us-west-2.amazonaws.com/ucsd.cogs9/readings/r5b_machine_bias.pdf" target="_blank" rel="noopener">download &#x2197;</a>

These readings focus less on how to build impressive machine learning models and more on the problems and pitfalls that come with using them. In class, weâ€™ll cover many of the powerful things you can do with data and algorithmsâ€”but itâ€™s just as important to understand where these tools break down. 

The issues discussed here arenâ€™t merely academic. Many of them show up in real, widely deployed machine learning systems, often because models learn patterns from flawed, biased, or incomplete data-generating processes. If we want to build technology that serves people and improves society, we need to be able to recognize when machine learning is failing, misleading, or being misapplied, and know how to respond responsibly.

## Reading Guide
- R5 Reading Guide <a href="https://docs.google.com/document/d/10RwVdwHpFzTpSqvF7kOG36IT8QtvXJmR0me3I282QeI/edit?usp=sharing" target="_blank" rel="noopener">open! &#x2197;</a>
  - This reading guide highlights the major ideas to focus on in the paper. **You will not turn in the guide**â€”itâ€™s simply here to help you distill the paper and keep track of the main points. Use it before you read (to preview what to look for), while you read (to take notes), and after you read (to review). It will also be a helpful reference when preparing for the reading quiz/exam!

## Additional Resources

Here is an interesting game you can <a href="https://www.survivalofthebestfit.com/" target="_blank" rel="noopener">play &#x2197;</a> that teaches you how algorithms learn to fit a bias from the data generating process, as well as, the decisions that people make using the system. Feedback loops can be very dangerous to a system, and with machine learning it can reinforce, at first, benign issues with data or decisions.

